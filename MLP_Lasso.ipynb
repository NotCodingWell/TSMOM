{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn import tree\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_features_single_asset(df,k,h, linear = False):\n",
    "    df = df.dropna(how='any',axis=0) \n",
    "    df['Cummulative Return'] = (1+ df['Return Daily']).cumprod(axis = 0)\n",
    "    df['Next H Return'] = df['Cummulative Return'].pct_change(h).shift(-h)\n",
    "    df['Mean H Return'] = df[\"Return Daily\"].rolling(h).apply(lambda x: x.iloc[range(0,h)].mean()).shift(-h + 1)\n",
    "    df['Square Sum Return'] = df[\"Return Daily\"].rolling(h).apply(lambda x: x.iloc[range(0,h)].pow(2).sum()).shift(-h + 1)\n",
    "    df['STD H Return'] = df[\"Return Daily\"].rolling(h).apply(lambda x: x.iloc[range(0,h)].std(ddof = 1)).shift(-h + 1)\n",
    "\n",
    "    for temp in range(k,0,-1):\n",
    "        df[\"Before \" + str(temp) + \" Day\" ] = df['Return Daily'].shift(periods = int(temp))\n",
    "\n",
    "    if linear == True:\n",
    "        df['Signal'] = [1 if x > 0 else -1 for x in df['Mean H Return']]\n",
    "\n",
    "    df = df.dropna(how='any',axis=0)\n",
    "    df = df[1:]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data,k,h,linear = False):\n",
    "    company = data.columns\n",
    "    features = []\n",
    "    for i in range(k,0,-1):\n",
    "        features.append(\"Before \" + str(i) + \" Day\")\n",
    "    features.append(\"Return Daily\")\n",
    "\n",
    "    X_train = pd.DataFrame(columns=features)\n",
    "    if linear == False:\n",
    "        y_train = pd.DataFrame(columns=[\"Mean H Return\",\"Square Sum Return\"])\n",
    "    elif linear == True:\n",
    "        y_train = pd.DataFrame(columns=[\"Signal\"])\n",
    "    for oo in company:\n",
    "        flag_h = 0\n",
    "        flag_k = k+1\n",
    "        df = data[[oo]].copy()\n",
    "        \n",
    "        df.columns = [\"Return Daily\"]\n",
    "\n",
    "        df = construct_features_single_asset(df,k,h,linear = linear)\n",
    "        \n",
    "        X_train = pd.concat([X_train,df[features]],axis = 0)\n",
    "        if linear == False:\n",
    "            y_train = pd.concat([y_train,df[[\"Mean H Return\",\"Square Sum Return\"]]],axis = 0)\n",
    "        elif linear == True:\n",
    "            y_train = pd.concat([y_train,df[[\"Signal\"]]],axis = 0)\n",
    "    return [X_train,y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_loss(h):\n",
    "    def calculation(y_target, y_pred):\n",
    "\n",
    "        mean = K.reshape(y_target[:, 0], (-1, 1))\n",
    "        square_sum =  K.reshape(y_target[:, 1], (-1, 1))\n",
    "\n",
    "        sum_pofolio = mean * h * y_pred\n",
    "        mean_pofolio = K.mean(mean * h * y_pred)\n",
    "\n",
    "        std_pofolio = tf.math.sqrt(K.mean(square_sum - 2 * sum_pofolio * mean_pofolio + mean_pofolio ** 2)/h)\n",
    "\n",
    "    \n",
    "        return  - (mean_pofolio / std_pofolio) *np.sqrt(252)\n",
    "    \n",
    "    return calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(data, k, h):\n",
    "\n",
    "    model = tree.DecisionTreeClassifier()\n",
    "\n",
    "    X_train,y_train = feature_engineering(data,k,h,linear = True)\n",
    "    X_train = np.array(X_train, dtype=np.float64)\n",
    "    y_train = np.array(y_train, dtype=np.float64)\n",
    "    model= model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(data, k, h):\n",
    "\n",
    "    model = xgb.XGBRegressor(objective=\"multi:softmax\", num_class = 2,random_state=42)\n",
    "\n",
    "    X_train,y_train = feature_engineering(data,k,h,linear = True)\n",
    "    X_train = np.array(X_train, dtype=np.float64)\n",
    "    y_train = np.array(y_train, dtype=np.float64)\n",
    "    y_train[y_train == -1] = 0\n",
    "    model= model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MLP_supervised(data, k, h):\n",
    "\n",
    "    model = Sequential([\n",
    "    Dropout(0, input_shape=(k+1,)),\n",
    "    Dense(20,activation = 'tanh'),\n",
    "    Dense(1,activation = 'tanh'),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "    X_train,y_train = feature_engineering(data,k,h,linear = True)\n",
    "    X_train = np.array(X_train, dtype=np.float64)\n",
    "    y_train = np.array(y_train, dtype=np.float64)\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size = 256, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lasso_supervised(data, k, h,lambda_val = .7):\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(1, input_shape = (k+1,),kernel_regularizer = l1(lambda_val))\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "    X_train,y_train = feature_engineering(data,k,h,linear = True)\n",
    "    X_train = np.array(X_train, dtype=np.float64)\n",
    "    y_train = np.array(y_train, dtype=np.float64)\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size = 256, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MLP_sharpeLoss(data, k, h):\n",
    "\n",
    "    model = Sequential([\n",
    "    Dropout(0, input_shape=(k+1,)),\n",
    "    Dense(20,activation = 'tanh'),\n",
    "    Dense(1,activation = 'tanh'),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=sharpe_loss(h = h))\n",
    "\n",
    "\n",
    "    X_train,y_train = feature_engineering(data,k,h,linear = False)\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100, batch_size = 256, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Lasso_sharpeLoss(data, k, h,lambda_val = .01):\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(1, input_shape = (k+1,),kernel_regularizer = l1(lambda_val))\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=sharpe_loss(h = h))\n",
    "\n",
    "    X_train,y_train = feature_engineering(data,k,h,linear = False)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size = 1024, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = '6mo' # khoảng thời gian làm backtest \n",
    "start_time = '2024-01-01'\n",
    "end_time = '2024-07-01'\n",
    "\n",
    "def EU_Stock_data():\n",
    "    \"\"\"Lấy dữ liệu giá Close của 50 công ty trên sàn Euro_STOXX 50 vào thời gian cho trước\"\"\"\n",
    "\n",
    "    stock_list = pd.read_html( 'https://en.wikipedia.org/wiki/EURO_STOXX_50')[4]['Ticker'][1:].to_list()\n",
    "    futures = pd.DataFrame(columns= stock_list) # danh sách mã\n",
    "    \n",
    "    # đặt index \n",
    "    time_index = list(yf.Ticker(stock_list[0]).history(period = time_range,start = start_time, end = end_time).index) \n",
    "\n",
    "    # xét từng mã\n",
    "    for symbol in stock_list:\n",
    "        df = yf.Ticker(symbol).history(period = time_range, start = start_time, end = end_time)\n",
    "        df = pd.DataFrame(df['Close']) # lấy giá close\n",
    "        i = 0\n",
    "        daily_return = []\n",
    "        # tinh daily return, = 0 trong ngày đầu tiên \n",
    "        for k in df['Close']:\n",
    "            if i != 0:\n",
    "                daily_return.append(float((k-i)/i))\n",
    "            else:\n",
    "                daily_return.append(float(0))\n",
    "            i = k\n",
    "        try:\n",
    "            futures[symbol] = daily_return\n",
    "        except:\n",
    "            while len(daily_return) < len(futures):\n",
    "                daily_return.insert(0,np.nan)\n",
    "            futures[symbol] = daily_return\n",
    "\n",
    "    futures.index = time_index\n",
    "\n",
    "    futures['Date'] = pd.to_datetime(futures.index, format='%Y-%m-%d')\n",
    "    futures.set_index('Date', inplace=True)\n",
    "\n",
    "    return futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_TSMOM(data, model,k,h,linear = False):\n",
    "\n",
    "    company = data.columns\n",
    "\n",
    "    signal = pd.DataFrame(index = data.index, columns= company)\n",
    "\n",
    "    features = []\n",
    "    for i in range(k,0,-1):\n",
    "        features.append(\"Before \" + str(i) + \" Day\")\n",
    "    features.append(\"Return Daily\")\n",
    "\n",
    "    for oo in company:\n",
    "        df = data[[oo]].copy()\n",
    "        \n",
    "        df.columns = [\"Return Daily\"]\n",
    "        df = construct_features_single_asset(df,k,h,linear = linear)\n",
    "\n",
    "        \n",
    "        X_test = df[features]\n",
    "        X_test['prediction'] = np.sign(model.predict(X_test))\n",
    "        X_test['prediction'][X_test['prediction'] == 0] = -1\n",
    "        for x,v in enumerate(X_test.index):\n",
    "            signal.loc[v,oo] = X_test.loc[v,'prediction']\n",
    "        \n",
    "        signal[oo] = signal[oo].ffill()\n",
    "        signal[oo] = signal[oo].fillna(0)\n",
    "\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Volatility_scale(data, ignore_na=False, adjust = True, com = 60, min_periods=0):\n",
    "    \"\"\"Scale data using ex ante volatility\"\"\"\n",
    "\n",
    "    # Lưu trữ index, tức thời gian \n",
    "    std_index = data.index\n",
    "\n",
    "    # chứa kết quả\n",
    "    daily_index = pd.DataFrame(index=std_index)\n",
    "\n",
    "    # xét từng cổ phiếu\n",
    "    for oo in data.columns:\n",
    "        returns = data[oo]  # Lấy ra các return\n",
    "        returns.dropna(inplace=True)  # xử lý null bằng zero\n",
    "\n",
    "        # Tính cumulative (cum) return , nhưng ko có thành phần - 1\n",
    "        ret_index = (1 + returns).cumprod()\n",
    "\n",
    "        # Tính daily volatility (vol)\n",
    "        day_vol = returns.ewm(ignore_na=ignore_na,\n",
    "                              adjust=adjust,\n",
    "                              com=com,\n",
    "                              min_periods=min_periods).std(bias=False)\n",
    "        \n",
    "        vol = day_vol * np.sqrt(252)  # scale lại theo 252 ngày active trading\n",
    "\n",
    "        # Join cum return và vol\n",
    "        ret_index = pd.concat([ret_index, vol], axis=1)\n",
    "        ret_index.columns = [oo, oo + '_Vol']  # Đặt tên cột cum return là tên cổ phiếu, bên cạnh là vol \n",
    "\n",
    "        # Join \n",
    "        daily_index = pd.concat([daily_index, ret_index], axis=1)\n",
    "\n",
    "    return daily_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_TSMOM(data, k, h, tolerance = 0,ignore_na = False, adjust = True, com = 60, min_periods = 0):\n",
    "    signal = pd.DataFrame(index = data.index)\n",
    "\n",
    "    # gọi hàm Volatility scale\n",
    "    daily_index = Volatility_scale(data,ignore_na=ignore_na,\n",
    "                          adjust=adjust,\n",
    "                          com=com,   \n",
    "                          min_periods = min_periods)\n",
    "\n",
    "    company = data.columns\n",
    "\n",
    "    for oo in company:\n",
    "        flag_h = 0\n",
    "        flag_k = k+1\n",
    "        df = pd.concat([daily_index[oo], daily_index[oo+\"_Vol\"]], axis=1)\n",
    "        df['rolling returns'] = df[oo].pct_change(k) # so sánh thay đổi ở ngày t với k ngày trước đó (tức t - k)\n",
    "        df['signal'] = 0.\n",
    "        for x, v in enumerate(df['rolling returns']):\n",
    "            if flag_h != 0:\n",
    "                # Bỏ qua giai đoạn hold, tránh bị tính lặp lại\n",
    "                flag_h = flag_h - 1\n",
    "                continue\n",
    "            # Bỏ qua thời gian cty chưa được lên sàn (nêu có)\n",
    "            if df[oo].isnull().iloc[x] == False:\n",
    "                # bỏ qua k ngày đầu vì chưa đủ k lookback\n",
    "                if flag_k != 0:\n",
    "                    flag_k = flag_k - 1\n",
    "                    continue\n",
    "            else: continue\n",
    "            try:\n",
    "                if df['rolling returns'].iloc[x-1] < tolerance:\n",
    "                    for h_period in range(0,h):\n",
    "                        # rolling return < 0, short rồi giữ trong h ngày, tính pnl, leverage///\n",
    "                        df['signal'].iloc[x + h_period] = -1\n",
    "                \n",
    "                elif df['rolling returns'].iloc[x-1] > tolerance:\n",
    "                    for h_period in range(0,h):\n",
    "                        # rolling return > 0, long rồi giữ trong h ngày, tính pnl, leverage///\n",
    "                        df['signal'].iloc[x + h_period] = 1\n",
    "\n",
    "            except:pass\n",
    "            \n",
    "\n",
    "            # Đặt flag holding là h - 1, để qua vòng for mới bỏ qua ngày hold, tránh bị tính lặp lại\n",
    "            if df['rolling returns'].iloc[x-1] != tolerance: flag_h = h - 1\n",
    "\n",
    "        signal = pd.concat([signal, df['signal']], axis=1)\n",
    "\n",
    "    signal.columns = data.columns\n",
    "    \n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data,signal,k,h,  vol_flag = 1, target_vol = 0.2, ignore_na = False, adjust = True, com = 60, min_periods = 0):\n",
    "    \n",
    "    pnl = pd.DataFrame(index=data.index)\n",
    "    leverage = pd.DataFrame(index = data.index)\n",
    "\n",
    "    # gọi hàm Volatility scale\n",
    "    daily_index = Volatility_scale(data,ignore_na=ignore_na,\n",
    "                          adjust=adjust,\n",
    "                          com=com,   \n",
    "                          min_periods = min_periods)\n",
    "\n",
    "    company = data.columns\n",
    "\n",
    "    # Volatility settings\n",
    "    vol_flag = vol_flag    # Set flag to 1 for vol targeting\n",
    "    if vol_flag == 1:\n",
    "        target_vol = target_vol \n",
    "    else:\n",
    "        target_vol = 'no target vol'\n",
    "    \n",
    "\n",
    "    for oo in company:\n",
    "        flag_h = 0\n",
    "        flag_k = k+1\n",
    "        df = pd.concat([daily_index[oo], daily_index[oo+\"_Vol\"]], axis=1)\n",
    "\n",
    "        df['pnl'] = 0. \n",
    "        df['leverage'] = 0.\n",
    "        for x, v in enumerate(df['pnl']):\n",
    "            if flag_h != 0:\n",
    "                # Bỏ qua giai đoạn hold, tránh bị tính lặp lại\n",
    "                flag_h = flag_h - 1\n",
    "                continue\n",
    "            # Bỏ qua thời gian cty chưa được lên sàn (nêu có)\n",
    "            if df[oo].isnull().iloc[x] == False:\n",
    "                # bỏ qua k ngày đầu vì chưa đủ k lookback\n",
    "                if flag_k != 0:\n",
    "                    flag_k = flag_k - 1\n",
    "                    continue\n",
    "            else: continue\n",
    "            try:\n",
    "                if signal[oo].iloc[x] == -1:\n",
    "                    for h_period in range(0,h):\n",
    "                        if vol_flag == 1:\n",
    "                            df['pnl'].iloc[x + h_period] = (1 - df[oo].iloc[x + h_period] / df[oo].iloc[x - 1 + h_period]) * \\\n",
    "                                target_vol / df[oo+\"_Vol\"].iloc[x -1] \n",
    "                            df['leverage'].iloc[x + h_period] = target_vol / df[oo+\"_Vol\"].iloc[x -1]\n",
    "                        else:\n",
    "                            df['pnl'].iloc[x + h_period] = (1 - df[oo].iloc[x + h_period] / df[oo].iloc[x - 1 + h_period])\n",
    "                            df['leverage'].iloc[x+h_period] = 1\n",
    "                elif signal[oo].iloc[x] == 1:\n",
    "                    for h_period in range(0,h):\n",
    "                        if vol_flag == 1:\n",
    "                            df['pnl'].iloc[x + h_period] = (df[oo].iloc[x + h_period] / df[oo].iloc[x - 1 + h_period] - 1) * \\\n",
    "                                    target_vol / df[oo+\"_Vol\"].iloc[x - 1]\n",
    "                            df['leverage'].iloc[x+h_period] = target_vol / df[oo+\"_Vol\"].iloc[x -1]\n",
    "                        else:\n",
    "                            df['pnl'].iloc[x + h_period] = (df[oo].iloc[x + h_period] / df[oo].iloc[x - 1 + h_period] - 1)\n",
    "                            df['leverage'].iloc[x+h_period] = 1\n",
    "            except:pass\n",
    "            \n",
    "            if signal[oo].iloc[x] == 1 or signal[oo].iloc[x] == -1 : flag_h = h - 1\n",
    "\n",
    "\n",
    "        leverage = pd.concat([leverage, df['leverage']], axis = 1)\n",
    "        pnl = pd.concat([pnl, df['pnl']], axis=1)\n",
    "\n",
    "    pnl.columns = data.columns\n",
    "    leverage.columns = data.columns\n",
    "\n",
    "    return [pnl,leverage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_daily_return(pnl):\n",
    "    \n",
    "    return pnl.mean(skipna = False, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -0.0350  \n",
      "Epoch 2/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -0.3543 \n",
      "Epoch 3/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -0.7185 \n",
      "Epoch 4/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -1.0113 \n",
      "Epoch 5/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.3798\n",
      "Epoch 6/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -1.6053 \n",
      "Epoch 7/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -2.1160 \n",
      "Epoch 8/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -2.3767 \n",
      "Epoch 9/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -2.7391\n",
      "Epoch 10/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -3.0139 \n",
      "Epoch 11/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -3.4369 \n",
      "Epoch 12/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -3.4282 \n",
      "Epoch 13/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -3.9787 \n",
      "Epoch 14/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -4.3475\n",
      "Epoch 15/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -4.7395 \n",
      "Epoch 16/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -5.6754\n",
      "Epoch 17/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -5.4473 \n",
      "Epoch 18/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -5.6397\n",
      "Epoch 19/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -6.0740 \n",
      "Epoch 20/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -6.1934 \n",
      "Epoch 21/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -6.5303 \n",
      "Epoch 22/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -7.1288 \n",
      "Epoch 23/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -7.1957\n",
      "Epoch 24/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -7.1791 \n",
      "Epoch 25/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -7.8693\n",
      "Epoch 26/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -8.6889 \n",
      "Epoch 27/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -8.7666\n",
      "Epoch 28/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -9.4798  \n",
      "Epoch 29/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -9.7524  \n",
      "Epoch 30/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -9.8845  \n",
      "Epoch 31/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -11.0162\n",
      "Epoch 32/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -9.6168 \n",
      "Epoch 33/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -10.1611 \n",
      "Epoch 34/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -11.2360\n",
      "Epoch 35/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -11.2857\n",
      "Epoch 36/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -11.5736 \n",
      "Epoch 37/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -11.4682\n",
      "Epoch 38/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -11.9258 \n",
      "Epoch 39/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -12.6222 \n",
      "Epoch 40/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -13.1607\n",
      "Epoch 41/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -13.5334 \n",
      "Epoch 42/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -14.9316 \n",
      "Epoch 43/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -14.2690\n",
      "Epoch 44/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -15.0529\n",
      "Epoch 45/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -15.3877 \n",
      "Epoch 46/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -15.5296 \n",
      "Epoch 47/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -15.2993\n",
      "Epoch 48/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: -16.6116 \n",
      "Epoch 49/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -16.9357\n",
      "Epoch 50/50\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -17.3726\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('Main File/TSMOM/Data/data_close.csv' , index_col= 'Date')\n",
    "test_data = EU_Stock_data()\n",
    "\n",
    "k = 10\n",
    "h = 15\n",
    "\n",
    "model_name = ['classic_TSMOM','train_decision_tree','train_xgboost','train_MLP_supervised','train_lasso_supervised','train_MLP_sharpeLoss','train_Lasso_sharpeLoss']\n",
    "\n",
    "for model in model_name:\n",
    "    func = globals()[model]\n",
    "    if model == 'classic_TSMOM':\n",
    "        pnl = strategy_daily_return(backtest(test_data,func(test_data,k,h),k,h)[0])\n",
    "    else:\n",
    "        temp_model = func(train_data,10,15)\n",
    "        pnl = strategy_daily_return(backtest(test_data,test_model_TSMOM(test_data,temp_model,k,h),k,h)[0])\n",
    "    try:\n",
    "        temp = pnl.to_list()\n",
    "        temp.insert(0,model)\n",
    "        stats.loc[len(stats.index)] = temp\n",
    "    except:\n",
    "        index = pnl.index.to_list()\n",
    "        index.insert(0,'Model')\n",
    "        stats = pd.DataFrame(columns = index)\n",
    "        temp = pnl.to_list()\n",
    "        temp.insert(0,model)\n",
    "        stats.loc[len(stats.index)] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>2024-01-02 00:00:00+01:00</th>\n",
       "      <th>2024-01-03 00:00:00+01:00</th>\n",
       "      <th>2024-01-04 00:00:00+01:00</th>\n",
       "      <th>2024-01-05 00:00:00+01:00</th>\n",
       "      <th>2024-01-08 00:00:00+01:00</th>\n",
       "      <th>2024-01-09 00:00:00+01:00</th>\n",
       "      <th>2024-01-10 00:00:00+01:00</th>\n",
       "      <th>2024-01-11 00:00:00+01:00</th>\n",
       "      <th>2024-01-12 00:00:00+01:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2024-06-17 00:00:00+02:00</th>\n",
       "      <th>2024-06-18 00:00:00+02:00</th>\n",
       "      <th>2024-06-19 00:00:00+02:00</th>\n",
       "      <th>2024-06-20 00:00:00+02:00</th>\n",
       "      <th>2024-06-21 00:00:00+02:00</th>\n",
       "      <th>2024-06-24 00:00:00+02:00</th>\n",
       "      <th>2024-06-25 00:00:00+02:00</th>\n",
       "      <th>2024-06-26 00:00:00+02:00</th>\n",
       "      <th>2024-06-27 00:00:00+02:00</th>\n",
       "      <th>2024-06-28 00:00:00+02:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classic_TSMOM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006402</td>\n",
       "      <td>-0.004838</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>-0.006243</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>-0.009205</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.002627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_decision_tree</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.001196</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.001989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_xgboost</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>-0.001442</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>-0.000575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_MLP_supervised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>-0.001691</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>-0.004651</td>\n",
       "      <td>0.009929</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>-0.004248</td>\n",
       "      <td>-0.003863</td>\n",
       "      <td>-0.001750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_lasso_supervised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>-0.002360</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>-0.004927</td>\n",
       "      <td>0.011131</td>\n",
       "      <td>-0.003775</td>\n",
       "      <td>-0.005797</td>\n",
       "      <td>-0.004686</td>\n",
       "      <td>-0.002447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_MLP_sharpeLoss</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>-0.001498</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>-0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_Lasso_sharpeLoss</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_Lasso_sharpeLoss</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>-0.002360</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>-0.004927</td>\n",
       "      <td>0.011131</td>\n",
       "      <td>-0.003775</td>\n",
       "      <td>-0.005797</td>\n",
       "      <td>-0.004686</td>\n",
       "      <td>-0.002447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  2024-01-02 00:00:00+01:00  \\\n",
       "0           classic_TSMOM                        0.0   \n",
       "1     train_decision_tree                        0.0   \n",
       "2           train_xgboost                        0.0   \n",
       "3    train_MLP_supervised                        0.0   \n",
       "4  train_lasso_supervised                        0.0   \n",
       "5    train_MLP_sharpeLoss                        0.0   \n",
       "6  train_Lasso_sharpeLoss                        0.0   \n",
       "7  train_Lasso_sharpeLoss                        0.0   \n",
       "\n",
       "   2024-01-03 00:00:00+01:00  2024-01-04 00:00:00+01:00  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "5                        0.0                        0.0   \n",
       "6                        0.0                        0.0   \n",
       "7                        0.0                        0.0   \n",
       "\n",
       "   2024-01-05 00:00:00+01:00  2024-01-08 00:00:00+01:00  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "5                        0.0                        0.0   \n",
       "6                        0.0                        0.0   \n",
       "7                        0.0                        0.0   \n",
       "\n",
       "   2024-01-09 00:00:00+01:00  2024-01-10 00:00:00+01:00  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "5                        0.0                        0.0   \n",
       "6                        0.0                        0.0   \n",
       "7                        0.0                        0.0   \n",
       "\n",
       "   2024-01-11 00:00:00+01:00  2024-01-12 00:00:00+01:00  ...  \\\n",
       "0                        0.0                        0.0  ...   \n",
       "1                        0.0                        0.0  ...   \n",
       "2                        0.0                        0.0  ...   \n",
       "3                        0.0                        0.0  ...   \n",
       "4                        0.0                        0.0  ...   \n",
       "5                        0.0                        0.0  ...   \n",
       "6                        0.0                        0.0  ...   \n",
       "7                        0.0                        0.0  ...   \n",
       "\n",
       "   2024-06-17 00:00:00+02:00  2024-06-18 00:00:00+02:00  \\\n",
       "0                  -0.006402                  -0.004838   \n",
       "1                   0.001823                  -0.000835   \n",
       "2                   0.001370                  -0.000441   \n",
       "3                   0.005564                   0.004349   \n",
       "4                   0.006410                   0.005911   \n",
       "5                   0.002897                   0.001626   \n",
       "6                   0.000000                   0.000000   \n",
       "7                   0.006410                   0.005911   \n",
       "\n",
       "   2024-06-19 00:00:00+02:00  2024-06-20 00:00:00+02:00  \\\n",
       "0                   0.002777                  -0.006243   \n",
       "1                  -0.000044                  -0.001196   \n",
       "2                  -0.001442                   0.000140   \n",
       "3                  -0.001691                   0.007339   \n",
       "4                  -0.002360                   0.008773   \n",
       "5                  -0.000833                   0.002939   \n",
       "6                   0.000000                   0.000000   \n",
       "7                  -0.002360                   0.008773   \n",
       "\n",
       "   2024-06-21 00:00:00+02:00  2024-06-24 00:00:00+02:00  \\\n",
       "0                   0.003719                  -0.009205   \n",
       "1                   0.000747                   0.001468   \n",
       "2                   0.000356                   0.000074   \n",
       "3                  -0.004651                   0.009929   \n",
       "4                  -0.004927                   0.011131   \n",
       "5                  -0.001498                   0.005715   \n",
       "6                   0.000000                   0.000000   \n",
       "7                  -0.004927                   0.011131   \n",
       "\n",
       "   2024-06-25 00:00:00+02:00  2024-06-26 00:00:00+02:00  \\\n",
       "0                   0.004129                   0.004359   \n",
       "1                   0.001998                   0.001791   \n",
       "2                   0.000421                   0.002667   \n",
       "3                   0.001411                  -0.004248   \n",
       "4                  -0.003775                  -0.005797   \n",
       "5                   0.001005                  -0.000600   \n",
       "6                   0.000000                   0.000000   \n",
       "7                  -0.003775                  -0.005797   \n",
       "\n",
       "   2024-06-27 00:00:00+02:00  2024-06-28 00:00:00+02:00  \n",
       "0                   0.003279                   0.002627  \n",
       "1                   0.000201                   0.001989  \n",
       "2                   0.000301                  -0.000575  \n",
       "3                  -0.003863                  -0.001750  \n",
       "4                  -0.004686                  -0.002447  \n",
       "5                  -0.000656                  -0.000901  \n",
       "6                   0.000000                   0.000000  \n",
       "7                  -0.004686                  -0.002447  \n",
       "\n",
       "[8 rows x 127 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>2024-01-02 00:00:00+01:00</th>\n",
       "      <th>2024-01-03 00:00:00+01:00</th>\n",
       "      <th>2024-01-04 00:00:00+01:00</th>\n",
       "      <th>2024-01-05 00:00:00+01:00</th>\n",
       "      <th>2024-01-08 00:00:00+01:00</th>\n",
       "      <th>2024-01-09 00:00:00+01:00</th>\n",
       "      <th>2024-01-10 00:00:00+01:00</th>\n",
       "      <th>2024-01-11 00:00:00+01:00</th>\n",
       "      <th>2024-01-12 00:00:00+01:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2024-06-17 00:00:00+02:00</th>\n",
       "      <th>2024-06-18 00:00:00+02:00</th>\n",
       "      <th>2024-06-19 00:00:00+02:00</th>\n",
       "      <th>2024-06-20 00:00:00+02:00</th>\n",
       "      <th>2024-06-21 00:00:00+02:00</th>\n",
       "      <th>2024-06-24 00:00:00+02:00</th>\n",
       "      <th>2024-06-25 00:00:00+02:00</th>\n",
       "      <th>2024-06-26 00:00:00+02:00</th>\n",
       "      <th>2024-06-27 00:00:00+02:00</th>\n",
       "      <th>2024-06-28 00:00:00+02:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classic_TSMOM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006402</td>\n",
       "      <td>-0.004838</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>-0.006243</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>-0.009205</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.002627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_decision_tree</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.001196</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.001989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_xgboost</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>-0.001442</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>-0.000575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_MLP_supervised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>-0.001691</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>-0.004651</td>\n",
       "      <td>0.009929</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>-0.004248</td>\n",
       "      <td>-0.003863</td>\n",
       "      <td>-0.001750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_lasso_supervised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>-0.002360</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>-0.004927</td>\n",
       "      <td>0.011131</td>\n",
       "      <td>-0.003775</td>\n",
       "      <td>-0.005797</td>\n",
       "      <td>-0.004686</td>\n",
       "      <td>-0.002447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_MLP_sharpeLoss</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>-0.001498</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>-0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_Lasso_sharpeLoss</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>-0.002360</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>-0.004927</td>\n",
       "      <td>0.011131</td>\n",
       "      <td>-0.003775</td>\n",
       "      <td>-0.005797</td>\n",
       "      <td>-0.004686</td>\n",
       "      <td>-0.002447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  2024-01-02 00:00:00+01:00  \\\n",
       "0           classic_TSMOM                        0.0   \n",
       "1     train_decision_tree                        0.0   \n",
       "2           train_xgboost                        0.0   \n",
       "3    train_MLP_supervised                        0.0   \n",
       "4  train_lasso_supervised                        0.0   \n",
       "5    train_MLP_sharpeLoss                        0.0   \n",
       "6  train_Lasso_sharpeLoss                        0.0   \n",
       "\n",
       "   2024-01-03 00:00:00+01:00  2024-01-04 00:00:00+01:00  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "5                        0.0                        0.0   \n",
       "6                        0.0                        0.0   \n",
       "\n",
       "   2024-01-05 00:00:00+01:00  2024-01-08 00:00:00+01:00  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "5                        0.0                        0.0   \n",
       "6                        0.0                        0.0   \n",
       "\n",
       "   2024-01-09 00:00:00+01:00  2024-01-10 00:00:00+01:00  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "5                        0.0                        0.0   \n",
       "6                        0.0                        0.0   \n",
       "\n",
       "   2024-01-11 00:00:00+01:00  2024-01-12 00:00:00+01:00  ...  \\\n",
       "0                        0.0                        0.0  ...   \n",
       "1                        0.0                        0.0  ...   \n",
       "2                        0.0                        0.0  ...   \n",
       "3                        0.0                        0.0  ...   \n",
       "4                        0.0                        0.0  ...   \n",
       "5                        0.0                        0.0  ...   \n",
       "6                        0.0                        0.0  ...   \n",
       "\n",
       "   2024-06-17 00:00:00+02:00  2024-06-18 00:00:00+02:00  \\\n",
       "0                  -0.006402                  -0.004838   \n",
       "1                   0.001823                  -0.000835   \n",
       "2                   0.001370                  -0.000441   \n",
       "3                   0.005564                   0.004349   \n",
       "4                   0.006410                   0.005911   \n",
       "5                   0.002897                   0.001626   \n",
       "6                   0.006410                   0.005911   \n",
       "\n",
       "   2024-06-19 00:00:00+02:00  2024-06-20 00:00:00+02:00  \\\n",
       "0                   0.002777                  -0.006243   \n",
       "1                  -0.000044                  -0.001196   \n",
       "2                  -0.001442                   0.000140   \n",
       "3                  -0.001691                   0.007339   \n",
       "4                  -0.002360                   0.008773   \n",
       "5                  -0.000833                   0.002939   \n",
       "6                  -0.002360                   0.008773   \n",
       "\n",
       "   2024-06-21 00:00:00+02:00  2024-06-24 00:00:00+02:00  \\\n",
       "0                   0.003719                  -0.009205   \n",
       "1                   0.000747                   0.001468   \n",
       "2                   0.000356                   0.000074   \n",
       "3                  -0.004651                   0.009929   \n",
       "4                  -0.004927                   0.011131   \n",
       "5                  -0.001498                   0.005715   \n",
       "6                  -0.004927                   0.011131   \n",
       "\n",
       "   2024-06-25 00:00:00+02:00  2024-06-26 00:00:00+02:00  \\\n",
       "0                   0.004129                   0.004359   \n",
       "1                   0.001998                   0.001791   \n",
       "2                   0.000421                   0.002667   \n",
       "3                   0.001411                  -0.004248   \n",
       "4                  -0.003775                  -0.005797   \n",
       "5                   0.001005                  -0.000600   \n",
       "6                  -0.003775                  -0.005797   \n",
       "\n",
       "   2024-06-27 00:00:00+02:00  2024-06-28 00:00:00+02:00  \n",
       "0                   0.003279                   0.002627  \n",
       "1                   0.000201                   0.001989  \n",
       "2                   0.000301                  -0.000575  \n",
       "3                  -0.003863                  -0.001750  \n",
       "4                  -0.004686                  -0.002447  \n",
       "5                  -0.000656                  -0.000901  \n",
       "6                  -0.004686                  -0.002447  \n",
       "\n",
       "[7 rows x 127 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = stats.reset_index(drop = True)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.to_csv(\"result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
