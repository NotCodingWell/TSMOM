{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_features_single_asset(df,k,h, linear = False):\n",
    "    df = df.dropna(how='any',axis=0) \n",
    "    df['Cummulative Return'] = (1+ df['Return Daily']).cumprod(axis = 0)\n",
    "    df['Next H Return'] = df['Cummulative Return'].pct_change(h).shift(-h)\n",
    "    df['Mean H Return'] = df[\"Return Daily\"].rolling(h).apply(lambda x: x.iloc[range(0,h)].mean()).shift(-h + 1)\n",
    "    df['Square Sum Return'] = df[\"Return Daily\"].rolling(h).apply(lambda x: x.iloc[range(0,h)].pow(2).sum()).shift(-h + 1)\n",
    "    df['STD H Return'] = df[\"Return Daily\"].rolling(h).apply(lambda x: x.iloc[range(0,h)].std(ddof = 1)).shift(-h + 1)\n",
    "\n",
    "    for temp in range(k,0,-1):\n",
    "        df[\"Before \" + str(temp) + \" Day\" ] = df['Return Daily'].shift(periods = int(temp))\n",
    "\n",
    "    if linear == True:\n",
    "        df['Signal'] = [1 if x > 0 else -1 for x in df['Mean H Return']]\n",
    "\n",
    "    df = df.dropna(how='any',axis=0)\n",
    "    df = df[1:]\n",
    "\n",
    "        \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_loss(h):\n",
    "    def calculation(y_target, y_pred):\n",
    "\n",
    "        mean = K.reshape(y_target[:, 0], (-1, 1))\n",
    "        square_sum =  K.reshape(y_target[:, 1], (-1, 1))\n",
    "\n",
    "        sum_pofolio = mean * h * tf.math.sign(y_pred)\n",
    "        mean_pofolio = K.mean(mean * y_pred * tf.math.sign(y_pred))\n",
    "\n",
    "        std_pofolio = tf.math.sqrt(K.mean(square_sum - 2 * sum_pofolio * mean_pofolio + mean_pofolio ** 2)/h)\n",
    "\n",
    "    \n",
    "        return  - (mean_pofolio / std_pofolio) *np.sqrt(252)\n",
    "    \n",
    "    return calculation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MLP_Loss(data, k, h):\n",
    "\n",
    "    model = Sequential([\n",
    "    Dropout(0, input_shape=(k+1,)),\n",
    "    Dense(20,activation = 'tanh'),\n",
    "    Dense(1,activation = 'tanh'),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=sharpe_loss(h = h))\n",
    "\n",
    "    company = data.columns\n",
    "    features = []\n",
    "    for i in range(k,0,-1):\n",
    "        features.append(\"Before \" + str(i) + \" Day\")\n",
    "    features.append(\"Return Daily\")\n",
    "\n",
    "    X_train = pd.DataFrame(columns=features)\n",
    "    y_train = pd.DataFrame(columns=[\"Mean H Return\",\"Square Sum Return\"])\n",
    "    for oo in company:\n",
    "        flag_h = 0\n",
    "        flag_k = k+1\n",
    "        df = data[[oo]].copy()\n",
    "        \n",
    "        df.columns = [\"Return Daily\"]\n",
    "\n",
    "        df = construct_features_single_asset(df,k,h,linear = False)\n",
    "        \n",
    "\n",
    "        X_train = pd.concat([X_train,df[features]],axis = 0)\n",
    "        y_train = pd.concat([y_train,df[[\"Mean H Return\",\"Square Sum Return\"]]],axis = 0)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size = 128, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: -0.1880\n",
      "Epoch 2/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4256\n",
      "Epoch 3/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4413\n",
      "Epoch 4/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4564\n",
      "Epoch 5/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4420\n",
      "Epoch 6/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4522\n",
      "Epoch 7/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4559\n",
      "Epoch 8/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4477\n",
      "Epoch 9/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: -0.4561\n",
      "Epoch 10/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4624\n",
      "Epoch 11/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.4295\n",
      "Epoch 12/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4400\n",
      "Epoch 13/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4492\n",
      "Epoch 14/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4330\n",
      "Epoch 15/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4585\n",
      "Epoch 16/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4775\n",
      "Epoch 17/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4633\n",
      "Epoch 18/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: -0.4367\n",
      "Epoch 19/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.4606\n",
      "Epoch 20/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.4712\n",
      "Epoch 21/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4731\n",
      "Epoch 22/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.4271\n",
      "Epoch 23/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.4680\n",
      "Epoch 24/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.4720\n",
      "Epoch 25/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5094\n",
      "Epoch 26/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5193\n",
      "Epoch 27/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5125\n",
      "Epoch 28/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5104\n",
      "Epoch 29/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5379\n",
      "Epoch 30/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5284\n",
      "Epoch 31/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -0.5435\n",
      "Epoch 32/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5096\n",
      "Epoch 33/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -0.5221\n",
      "Epoch 34/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5212\n",
      "Epoch 35/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5442\n",
      "Epoch 36/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5660\n",
      "Epoch 37/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5380\n",
      "Epoch 38/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5322\n",
      "Epoch 39/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5400\n",
      "Epoch 40/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5244\n",
      "Epoch 41/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5308\n",
      "Epoch 42/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5308\n",
      "Epoch 43/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5350\n",
      "Epoch 44/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5301\n",
      "Epoch 45/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5259\n",
      "Epoch 46/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5004\n",
      "Epoch 47/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5294\n",
      "Epoch 48/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5425\n",
      "Epoch 49/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5145\n",
      "Epoch 50/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5246\n",
      "Epoch 51/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.4943\n",
      "Epoch 52/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5375\n",
      "Epoch 53/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5244\n",
      "Epoch 54/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5265\n",
      "Epoch 55/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5570\n",
      "Epoch 56/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5439\n",
      "Epoch 57/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5073\n",
      "Epoch 58/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5205\n",
      "Epoch 59/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5546\n",
      "Epoch 60/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5434\n",
      "Epoch 61/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5293\n",
      "Epoch 62/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5271\n",
      "Epoch 63/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5634\n",
      "Epoch 64/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5337\n",
      "Epoch 65/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5294\n",
      "Epoch 66/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5542\n",
      "Epoch 67/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5336\n",
      "Epoch 68/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5125\n",
      "Epoch 69/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5646\n",
      "Epoch 70/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5186\n",
      "Epoch 71/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5301\n",
      "Epoch 72/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5075\n",
      "Epoch 73/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4954\n",
      "Epoch 74/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5072\n",
      "Epoch 75/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.5096\n",
      "Epoch 76/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.5433\n",
      "Epoch 77/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5221\n",
      "Epoch 78/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5207\n",
      "Epoch 79/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5292\n",
      "Epoch 80/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5287\n",
      "Epoch 81/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5145\n",
      "Epoch 82/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: -0.5240\n",
      "Epoch 83/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5527\n",
      "Epoch 84/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5247\n",
      "Epoch 85/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5073\n",
      "Epoch 86/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5005\n",
      "Epoch 87/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5206\n",
      "Epoch 88/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5430\n",
      "Epoch 89/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5459\n",
      "Epoch 90/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: -0.5262\n",
      "Epoch 91/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5576\n",
      "Epoch 92/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5408\n",
      "Epoch 93/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5217\n",
      "Epoch 94/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5263\n",
      "Epoch 95/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5294\n",
      "Epoch 96/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5123\n",
      "Epoch 97/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: -0.5164\n",
      "Epoch 98/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.4919\n",
      "Epoch 99/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.5232\n",
      "Epoch 100/100\n",
      "\u001b[1m382/382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.5281\n"
     ]
    }
   ],
   "source": [
    "model = train_MLP_Loss(pd.read_csv('Data/data_close.csv' , index_col= 'Date'),10,15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = '6mo' # khoảng thời gian làm backtest \n",
    "start_time = '2024-01-01'\n",
    "end_time = '2024-07-01'\n",
    "\n",
    "def EU_Stock_data():\n",
    "    \"\"\"Lấy dữ liệu giá Close của 50 công ty trên sàn Euro_STOXX 50 vào thời gian cho trước\"\"\"\n",
    "\n",
    "    stock_list = pd.read_html( 'https://en.wikipedia.org/wiki/EURO_STOXX_50')[4]['Ticker'][1:].to_list()\n",
    "    futures = pd.DataFrame(columns= stock_list) # danh sách mã\n",
    "    \n",
    "    # đặt index \n",
    "    time_index = list(yf.Ticker(stock_list[0]).history(period = time_range,start = start_time, end = end_time).index) \n",
    "\n",
    "    # xét từng mã\n",
    "    for symbol in stock_list:\n",
    "        df = yf.Ticker(symbol).history(period = time_range, start = start_time, end = end_time)\n",
    "        df = pd.DataFrame(df['Close']) # lấy giá close\n",
    "        i = 0\n",
    "        daily_return = []\n",
    "        # tinh daily return, = 0 trong ngày đầu tiên \n",
    "        for k in df['Close']:\n",
    "            if i != 0:\n",
    "                daily_return.append(float((k-i)/i))\n",
    "            else:\n",
    "                daily_return.append(float(0))\n",
    "            i = k\n",
    "        try:\n",
    "            futures[symbol] = daily_return\n",
    "        except:\n",
    "            while len(daily_return) < len(futures):\n",
    "                daily_return.insert(0,np.nan)\n",
    "            futures[symbol] = daily_return\n",
    "\n",
    "    futures.index = time_index\n",
    "\n",
    "    futures['Date'] = pd.to_datetime(futures.index, format='%Y-%m-%d')\n",
    "    futures.set_index('Date', inplace=True)\n",
    "\n",
    "    return futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_TSMOM(data, model,k,h):\n",
    "\n",
    "    company = data.columns\n",
    "\n",
    "    signal = pd.DataFrame(index = data.index, columns= company)\n",
    "\n",
    "    features = []\n",
    "    for i in range(k,0,-1):\n",
    "        features.append(\"Before \" + str(i) + \" Day\")\n",
    "    features.append(\"Return Daily\")\n",
    "\n",
    "    for oo in company:\n",
    "        df = data[[oo]].copy()\n",
    "        \n",
    "        df.columns = [\"Return Daily\"]\n",
    "        df = construct_features_single_asset(df,k,h,linear = False)\n",
    "\n",
    "        \n",
    "        X_test = df[features]\n",
    "        X_test['prediction'] = np.sign(model.predict(X_test))\n",
    "        for x,v in enumerate(X_test.index):\n",
    "            signal.loc[v,oo] = X_test.loc[v,'prediction']\n",
    "        \n",
    "        signal[oo] = signal[oo].ffill()\n",
    "        signal[oo] = signal[oo].fillna(0)\n",
    "\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "signal = test_model_TSMOM(pd.read_csv('Data/data_close.csv' , index_col= 'Date'),model,10,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.to_csv(\"test_signal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Volatility_scale(data, ignore_na=False, adjust = True, com = 60, min_periods=0):\n",
    "    \"\"\"Scale data using ex ante volatility\"\"\"\n",
    "\n",
    "    # Lưu trữ index, tức thời gian \n",
    "    std_index = data.index\n",
    "\n",
    "    # chứa kết quả\n",
    "    daily_index = pd.DataFrame(index=std_index)\n",
    "\n",
    "    # xét từng cổ phiếu\n",
    "    for oo in data.columns:\n",
    "        returns = data[oo]  # Lấy ra các return\n",
    "        returns.dropna(inplace=True)  # xử lý null bằng zero\n",
    "\n",
    "        # Tính cumulative (cum) return , nhưng ko có thành phần - 1\n",
    "        ret_index = (1 + returns).cumprod()\n",
    "\n",
    "        # Tính daily volatility (vol)\n",
    "        day_vol = returns.ewm(ignore_na=ignore_na,\n",
    "                              adjust=adjust,\n",
    "                              com=com,\n",
    "                              min_periods=min_periods).std(bias=False)\n",
    "        \n",
    "        vol = day_vol * np.sqrt(252)  # scale lại theo 252 ngày active trading\n",
    "\n",
    "        # Join cum return và vol\n",
    "        ret_index = pd.concat([ret_index, vol], axis=1)\n",
    "        ret_index.columns = [oo, oo + '_Vol']  # Đặt tên cột cum return là tên cổ phiếu, bên cạnh là vol \n",
    "\n",
    "        # Join \n",
    "        daily_index = pd.concat([daily_index, ret_index], axis=1)\n",
    "\n",
    "    return daily_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data,signal,k,h,  vol_flag = 1, target_vol = 0.2, ignore_na = False, adjust = True, com = 60, min_periods = 0):\n",
    "    \n",
    "    pnl = pd.DataFrame(index=data.index)\n",
    "    leverage = pd.DataFrame(index = data.index)\n",
    "\n",
    "    # gọi hàm Volatility scale\n",
    "    daily_index = Volatility_scale(data,ignore_na=ignore_na,\n",
    "                          adjust=adjust,\n",
    "                          com=com,   \n",
    "                          min_periods = min_periods)\n",
    "\n",
    "    company = data.columns\n",
    "\n",
    "    # Volatility settings\n",
    "    vol_flag = vol_flag    # Set flag to 1 for vol targeting\n",
    "    if vol_flag == 1:\n",
    "        target_vol = target_vol \n",
    "    else:\n",
    "        target_vol = 'no target vol'\n",
    "    \n",
    "\n",
    "    for oo in company:\n",
    "        flag_h = 0\n",
    "        flag_k = k+1\n",
    "        df = pd.concat([daily_index[oo], daily_index[oo+\"_Vol\"]], axis=1)\n",
    "\n",
    "        df['pnl'] = 0. \n",
    "        df['leverage'] = 0.\n",
    "        for x, v in enumerate(df['pnl']):\n",
    "            if flag_h != 0:\n",
    "                # Bỏ qua giai đoạn hold, tránh bị tính lặp lại\n",
    "                flag_h = flag_h - 1\n",
    "                continue\n",
    "            # Bỏ qua thời gian cty chưa được lên sàn (nêu có)\n",
    "            if df[oo].isnull().iloc[x] == False:\n",
    "                # bỏ qua k ngày đầu vì chưa đủ k lookback\n",
    "                if flag_k != 0:\n",
    "                    flag_k = flag_k - 1\n",
    "                    continue\n",
    "            else: continue\n",
    "            try:\n",
    "                if signal[oo].iloc[x] == -1:\n",
    "                    for h_period in range(0,h):\n",
    "                        if vol_flag == 1:\n",
    "                            df['pnl'].iloc[x + h_period] = (1 - df[oo].iloc[x + h_period] / df[oo].iloc[x - 1 + h_period]) * \\\n",
    "                                target_vol / df[oo+\"_Vol\"].iloc[x -1] \n",
    "                            df['leverage'].iloc[x + h_period] = target_vol / df[oo+\"_Vol\"].iloc[x -1]\n",
    "                        else:\n",
    "                            df['pnl'].iloc[x + h_period] = (1 - df[oo].iloc[x + h_period] / df[oo].iloc[x - 1 + h_period])\n",
    "                            df['leverage'].iloc[x+h_period] = 1\n",
    "                elif signal[oo].iloc[x] == 1:\n",
    "                    for h_period in range(0,h):\n",
    "                        if vol_flag == 1:\n",
    "                            df['pnl'].iloc[x + h_period] = (df[oo].iloc[x + h_period] / df[oo].iloc[x - 1 + h_period] - 1) * \\\n",
    "                                    target_vol / df[oo+\"_Vol\"].iloc[x - 1]\n",
    "                            df['leverage'].iloc[x+h_period] = target_vol / df[oo+\"_Vol\"].iloc[x -1]\n",
    "                        else:\n",
    "                            df['pnl'].iloc[x + h_period] = (df[oo].iloc[x + h_period] / df[oo].iloc[x - 1 + h_period] - 1)\n",
    "                            df['leverage'].iloc[x+h_period] = 1\n",
    "            except:pass\n",
    "            \n",
    "            if signal[oo].iloc[x] == 1 or signal[oo].iloc[x] == -1 : flag_h = h - 1\n",
    "\n",
    "\n",
    "        leverage = pd.concat([leverage, df['leverage']], axis = 1)\n",
    "        pnl = pd.concat([pnl, df['pnl']], axis=1)\n",
    "\n",
    "    pnl.columns = data.columns\n",
    "    leverage.columns = data.columns\n",
    "\n",
    "    return [pnl,leverage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1,df2 = backtest(pd.read_csv('Data/data_close.csv' , index_col= 'Date'), signal, 10,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADYEN.AS</th>\n",
       "      <th>AD.AS</th>\n",
       "      <th>AI.PA</th>\n",
       "      <th>AIR.PA</th>\n",
       "      <th>ALV.DE</th>\n",
       "      <th>ABI.BR</th>\n",
       "      <th>ASML.AS</th>\n",
       "      <th>CS.PA</th>\n",
       "      <th>BAS.DE</th>\n",
       "      <th>BAYN.DE</th>\n",
       "      <th>...</th>\n",
       "      <th>SGO.PA</th>\n",
       "      <th>SAN.PA</th>\n",
       "      <th>SAP.DE</th>\n",
       "      <th>SU.PA</th>\n",
       "      <th>SIE.DE</th>\n",
       "      <th>STLAM.MI</th>\n",
       "      <th>TTE.PA</th>\n",
       "      <th>DG.PA</th>\n",
       "      <th>UCG.MI</th>\n",
       "      <th>VOW.DE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-31 00:00:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02 00:00:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 00:00:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06 00:00:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07 00:00:00+01:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-21 00:00:00+01:00</th>\n",
       "      <td>-0.001070</td>\n",
       "      <td>-0.003247</td>\n",
       "      <td>-0.005441</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>-0.003271</td>\n",
       "      <td>-0.008909</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003474</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>-0.012272</td>\n",
       "      <td>-0.002656</td>\n",
       "      <td>-0.003236</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.002317</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>-0.017147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22 00:00:00+01:00</th>\n",
       "      <td>0.000279</td>\n",
       "      <td>-0.005174</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.014786</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.004842</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>-0.001969</td>\n",
       "      <td>-0.000759</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>-0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27 00:00:00+01:00</th>\n",
       "      <td>0.002069</td>\n",
       "      <td>-0.003275</td>\n",
       "      <td>-0.004083</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>-0.004899</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.012162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>-0.001092</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>-0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 00:00:00+01:00</th>\n",
       "      <td>-0.001735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004702</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>-0.005737</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>-0.006304</td>\n",
       "      <td>-0.001169</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004122</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>-0.002461</td>\n",
       "      <td>-0.001670</td>\n",
       "      <td>-0.001708</td>\n",
       "      <td>-0.016288</td>\n",
       "      <td>-0.010482</td>\n",
       "      <td>-0.001801</td>\n",
       "      <td>-0.019614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 00:00:00+01:00</th>\n",
       "      <td>-0.000596</td>\n",
       "      <td>-0.001739</td>\n",
       "      <td>-0.000609</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>-0.004699</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>-0.001208</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>-0.001331</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.005266</td>\n",
       "      <td>0.012690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1028 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ADYEN.AS     AD.AS     AI.PA    AIR.PA    ALV.DE  \\\n",
       "Date                                                                          \n",
       "2019-12-31 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-02 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-03 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-06 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-07 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "2023-12-21 00:00:00+01:00 -0.001070 -0.003247 -0.005441  0.004980 -0.003271   \n",
       "2023-12-22 00:00:00+01:00  0.000279 -0.005174  0.004704  0.007126  0.005191   \n",
       "2023-12-27 00:00:00+01:00  0.002069 -0.003275 -0.004083 -0.000154 -0.004899   \n",
       "2023-12-28 00:00:00+01:00 -0.001735  0.000000 -0.004702  0.002001 -0.005737   \n",
       "2023-12-29 00:00:00+01:00 -0.000596 -0.001739 -0.000609  0.000768  0.007134   \n",
       "\n",
       "                             ABI.BR   ASML.AS     CS.PA    BAS.DE   BAYN.DE  \\\n",
       "Date                                                                          \n",
       "2019-12-31 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-02 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-03 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-06 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-07 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "2023-12-21 00:00:00+01:00 -0.008909  0.003614  0.006348  0.000336  0.000965   \n",
       "2023-12-22 00:00:00+01:00  0.014786  0.001124  0.004842  0.001174  0.001444   \n",
       "2023-12-27 00:00:00+01:00 -0.001477  0.001459 -0.002516  0.001842  0.012162   \n",
       "2023-12-28 00:00:00+01:00  0.001109  0.001120 -0.006304 -0.001169  0.000391   \n",
       "2023-12-29 00:00:00+01:00  0.000923 -0.004699  0.002534  0.003346  0.002188   \n",
       "\n",
       "                           ...    SGO.PA    SAN.PA    SAP.DE     SU.PA  \\\n",
       "Date                       ...                                           \n",
       "2019-12-31 00:00:00+01:00  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-02 00:00:00+01:00  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-03 00:00:00+01:00  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-06 00:00:00+01:00  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-07 00:00:00+01:00  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "...                        ...       ...       ...       ...       ...   \n",
       "2023-12-21 00:00:00+01:00  ... -0.003474 -0.001351 -0.012272 -0.002656   \n",
       "2023-12-22 00:00:00+01:00  ...  0.006976  0.002451  0.005059  0.002389   \n",
       "2023-12-27 00:00:00+01:00  ...  0.000932 -0.001092  0.012205  0.004306   \n",
       "2023-12-28 00:00:00+01:00  ... -0.004122  0.000579 -0.001508 -0.002461   \n",
       "2023-12-29 00:00:00+01:00  ...  0.003607  0.003214 -0.001208  0.001920   \n",
       "\n",
       "                             SIE.DE  STLAM.MI    TTE.PA     DG.PA    UCG.MI  \\\n",
       "Date                                                                          \n",
       "2019-12-31 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-02 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-03 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-06 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-01-07 00:00:00+01:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "2023-12-21 00:00:00+01:00 -0.003236  0.000190 -0.002317  0.000240 -0.000151   \n",
       "2023-12-22 00:00:00+01:00 -0.001969 -0.000759  0.004645  0.008876  0.002412   \n",
       "2023-12-27 00:00:00+01:00  0.003651  0.000190  0.002619  0.000715  0.000902   \n",
       "2023-12-28 00:00:00+01:00 -0.001670 -0.001708 -0.016288 -0.010482 -0.001801   \n",
       "2023-12-29 00:00:00+01:00  0.007087 -0.001331  0.002970  0.001681  0.005266   \n",
       "\n",
       "                             VOW.DE  \n",
       "Date                                 \n",
       "2019-12-31 00:00:00+01:00  0.000000  \n",
       "2020-01-02 00:00:00+01:00  0.000000  \n",
       "2020-01-03 00:00:00+01:00  0.000000  \n",
       "2020-01-06 00:00:00+01:00  0.000000  \n",
       "2020-01-07 00:00:00+01:00  0.000000  \n",
       "...                             ...  \n",
       "2023-12-21 00:00:00+01:00 -0.017147  \n",
       "2023-12-22 00:00:00+01:00 -0.001030  \n",
       "2023-12-27 00:00:00+01:00 -0.000688  \n",
       "2023-12-28 00:00:00+01:00 -0.019614  \n",
       "2023-12-29 00:00:00+01:00  0.012690  \n",
       "\n",
       "[1028 rows x 49 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Lasso_Loss(data, k, h,lambda_val = .7):\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(1, input_shape = (k+1,),kernel_regularizer = l1(lambda_val))\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=sharpe_loss(h = h))\n",
    "\n",
    "    company = data.columns\n",
    "\n",
    "    features = []\n",
    "    for i in range(k,0,-1):\n",
    "        features.append(\"Before \" + str(i) + \" Day\")\n",
    "    features.append(\"Return Daily\")\n",
    "\n",
    "    X_train = pd.DataFrame(columns=features)\n",
    "    y_train = pd.DataFrame(columns=[\"Mean H Return\",\"Square Sum Return\"])\n",
    "    for oo in company:\n",
    "        flag_h = 0\n",
    "        flag_k = k+1\n",
    "        df = data[[oo]].copy()\n",
    "        \n",
    "        df.columns = [\"Return Daily\"]\n",
    "\n",
    "        df = construct_features_single_asset(df,k,h,linear = False)\n",
    "        \n",
    "\n",
    "        X_train = pd.concat([X_train,df[features]],axis = 0)\n",
    "        y_train = pd.concat([y_train,df[[\"Mean H Return\",\"Square Sum Return\"]]],axis = 0)\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size = 64, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.6949\n",
      "Epoch 2/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -0.2861\n",
      "Epoch 3/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -0.5383\n",
      "Epoch 4/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: -0.7911\n",
      "Epoch 5/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -1.0060\n",
      "Epoch 6/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -1.1770\n",
      "Epoch 7/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -1.5226\n",
      "Epoch 8/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -1.6216\n",
      "Epoch 9/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -1.8368\n",
      "Epoch 10/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: -2.1997\n",
      "Epoch 11/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: -2.3830\n",
      "Epoch 12/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -2.6082\n",
      "Epoch 13/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: -2.5764\n",
      "Epoch 14/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -3.1511\n",
      "Epoch 15/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: -3.1370\n",
      "Epoch 16/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: -3.4113\n",
      "Epoch 17/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: -3.4633\n",
      "Epoch 18/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -3.8608\n",
      "Epoch 19/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -3.9827\n",
      "Epoch 20/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -4.1439\n",
      "Epoch 21/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -4.5917\n",
      "Epoch 22/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -4.5900\n",
      "Epoch 23/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -4.6451\n",
      "Epoch 24/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -4.8432\n",
      "Epoch 25/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -5.2510\n",
      "Epoch 26/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -5.4456\n",
      "Epoch 27/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -5.9913\n",
      "Epoch 28/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -6.2421\n",
      "Epoch 29/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -6.6749\n",
      "Epoch 30/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -6.3218\n",
      "Epoch 31/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -6.7140\n",
      "Epoch 32/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -7.0286\n",
      "Epoch 33/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -6.8318\n",
      "Epoch 34/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -7.2502\n",
      "Epoch 35/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -7.4911\n",
      "Epoch 36/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -7.5186\n",
      "Epoch 37/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -7.7884\n",
      "Epoch 38/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -8.0710\n",
      "Epoch 39/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -7.9341\n",
      "Epoch 40/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -8.3169\n",
      "Epoch 41/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -8.5033\n",
      "Epoch 42/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -8.3409\n",
      "Epoch 43/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -8.6893\n",
      "Epoch 44/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -8.9429\n",
      "Epoch 45/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -9.3447\n",
      "Epoch 46/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -8.5009\n",
      "Epoch 47/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -9.1052\n",
      "Epoch 48/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: -9.4135\n",
      "Epoch 49/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -9.5004\n",
      "Epoch 50/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -10.1780\n",
      "Epoch 51/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -10.4078\n",
      "Epoch 52/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -9.8712\n",
      "Epoch 53/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: -10.6485\n",
      "Epoch 54/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -10.5498\n",
      "Epoch 55/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -10.6616\n",
      "Epoch 56/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: -11.0315\n",
      "Epoch 57/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: -10.7557\n",
      "Epoch 58/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: -11.2442\n",
      "Epoch 59/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -11.6713\n",
      "Epoch 60/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -11.4386\n",
      "Epoch 61/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -12.1332\n",
      "Epoch 62/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -11.7307\n",
      "Epoch 63/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -12.1589\n",
      "Epoch 64/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -11.9980\n",
      "Epoch 65/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -11.9430\n",
      "Epoch 66/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -12.2820\n",
      "Epoch 67/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -12.9965\n",
      "Epoch 68/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -12.8404\n",
      "Epoch 69/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -13.1677\n",
      "Epoch 70/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: -13.7201\n",
      "Epoch 71/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -14.2130\n",
      "Epoch 72/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -13.5892\n",
      "Epoch 73/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: -13.6595\n",
      "Epoch 74/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -13.6867\n",
      "Epoch 75/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -13.3761\n",
      "Epoch 76/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -13.6769\n",
      "Epoch 77/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -14.2622\n",
      "Epoch 78/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: -14.8736\n",
      "Epoch 79/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -14.3698\n",
      "Epoch 80/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -15.2860\n",
      "Epoch 81/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: -14.7851\n",
      "Epoch 82/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -15.2265\n",
      "Epoch 83/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: -13.9929\n",
      "Epoch 84/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -13.8004\n",
      "Epoch 85/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: -14.6119\n",
      "Epoch 86/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: -14.3960\n",
      "Epoch 87/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -13.9754\n",
      "Epoch 88/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -15.5984\n",
      "Epoch 89/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -15.8840\n",
      "Epoch 90/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -15.5491\n",
      "Epoch 91/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: -14.6873\n",
      "Epoch 92/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -15.5483\n",
      "Epoch 93/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: -14.7939\n",
      "Epoch 94/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: -16.0729\n",
      "Epoch 95/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: -16.4872\n",
      "Epoch 96/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: -16.0588\n",
      "Epoch 97/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: -16.0891\n",
      "Epoch 98/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: -17.2404\n",
      "Epoch 99/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -17.1855\n",
      "Epoch 100/100\n",
      "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: -17.9129\n"
     ]
    }
   ],
   "source": [
    "model = train_Lasso_Loss(pd.read_csv('Data/data_close.csv' , index_col= 'Date'),10,15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
