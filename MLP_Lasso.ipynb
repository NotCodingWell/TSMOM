{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn import tree\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_features_single_asset(df,k,h, linear = False, test = False):\n",
    "    df = df.dropna(how='any',axis=0) \n",
    "    df['Cummulative Return'] = (1+ df['Return Daily']).cumprod(axis = 0)\n",
    "    df['Next H Return'] = df['Cummulative Return'].pct_change(h).shift(-h)\n",
    "    df['Mean H Return'] = df[\"Return Daily\"].rolling(h).apply(lambda x: x.iloc[range(0,h)].mean()).shift(-h + 1)\n",
    "    df['Square Sum Return'] = df[\"Return Daily\"].rolling(h).apply(lambda x: x.iloc[range(0,h)].pow(2).sum()).shift(-h + 1)\n",
    "    df['STD H Return'] = df[\"Return Daily\"].rolling(h).apply(lambda x: x.iloc[range(0,h)].std(ddof = 1)).shift(-h + 1)\n",
    "\n",
    "    for temp in range(k,0,-1):\n",
    "        df[\"Before \" + str(temp) + \" Day\" ] = df['Return Daily'].shift(periods = int(temp))\n",
    "\n",
    "    if linear == True:\n",
    "        df['Signal'] = [1 if x > 0 else -1 for x in df['Mean H Return']]\n",
    "    \n",
    "    if test == True:\n",
    "        df = df.dropna(how='any',axis=0)\n",
    "        df = df[1:]\n",
    "        temp = pd.DataFrame(columns= df.columns)\n",
    "        n = 0\n",
    "        while True:\n",
    "            try:\n",
    "                temp = pd.concat([temp,df.iloc[[n*h],:]], axis = 0)\n",
    "                n = n+1\n",
    "            except: break\n",
    "        df = temp\n",
    "    else:\n",
    "        df = df.dropna(how='any',axis=0)\n",
    "        df = df[1:]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data,k,h,linear = False):\n",
    "    company = data.columns\n",
    "    features = []\n",
    "    for i in range(k,0,-1):\n",
    "        features.append(\"Before \" + str(i) + \" Day\")\n",
    "    features.append(\"Return Daily\")\n",
    "\n",
    "    X_train = pd.DataFrame(columns=features)\n",
    "    if linear == False:\n",
    "        y_train = pd.DataFrame(columns=[\"Mean H Return\",\"Square Sum Return\"])\n",
    "    elif linear == True:\n",
    "        y_train = pd.DataFrame(columns=[\"Signal\"])\n",
    "    for oo in company:\n",
    "        df = data[[oo]].copy()\n",
    "        \n",
    "        df.columns = [\"Return Daily\"]\n",
    "\n",
    "        df = construct_features_single_asset(df,k,h,linear = linear)\n",
    "        \n",
    "        X_train = pd.concat([X_train,df[features]],axis = 0)\n",
    "        if linear == False:\n",
    "            y_train = pd.concat([y_train,df[[\"Mean H Return\",\"Square Sum Return\"]]],axis = 0)\n",
    "        elif linear == True:\n",
    "            y_train = pd.concat([y_train,df[[\"Signal\"]]],axis = 0)\n",
    "    return [X_train,y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_loss(h):\n",
    "    def calculation(y_target_dummy, y_pred):\n",
    "\n",
    "        mean = K.reshape(y_target_dummy[:, 0], (-1, 1))\n",
    "        square_sum =  K.reshape(y_target_dummy[:, 1], (-1, 1))\n",
    "\n",
    "        sum_pofolio = mean * h * y_pred\n",
    "        mean_pofolio = K.mean(mean * h * y_pred) / h\n",
    "\n",
    "        std_pofolio = tf.math.sqrt(K.mean(square_sum * y_pred **2 \n",
    "                                          - 2 * sum_pofolio * y_pred * mean_pofolio \n",
    "                                          + mean_pofolio ** 2)/h)\n",
    "\n",
    "    \n",
    "        return  - (mean_pofolio / std_pofolio) *np.sqrt(252)\n",
    "    \n",
    "    return calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(data, k, h):\n",
    "\n",
    "    model = tree.DecisionTreeClassifier()\n",
    "\n",
    "    X_train,y_train = feature_engineering(data,k,h,linear = True)\n",
    "    X_train = np.array(X_train, dtype=np.float64)\n",
    "    y_train = np.array(y_train, dtype=np.float64)\n",
    "    model= model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(data, k, h):\n",
    "\n",
    "    model = xgb.XGBRegressor(objective=\"multi:softmax\", num_class = 2,random_state=42)\n",
    "\n",
    "    X_train,y_train = feature_engineering(data,k,h,linear = True)\n",
    "    X_train = np.array(X_train, dtype=np.float64)\n",
    "    y_train = np.array(y_train, dtype=np.float64)\n",
    "    y_train[y_train == -1] = 0\n",
    "    model= model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MLP_supervised(data, k, h, data_val = None):\n",
    "\n",
    "    model = Sequential([\n",
    "    Dropout(0, input_shape=(k+1,)),\n",
    "    Dense(5,activation = 'tanh'),\n",
    "    Dense(1,activation = 'sigmoid'),\n",
    "    ])\n",
    "\n",
    "    checkpoint_filepath = 'Test/Data/checkpoint.model.keras'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "    X_train,y_train = feature_engineering(data,k,h,linear = True)\n",
    "    y_train[y_train == -1] = 0\n",
    "\n",
    "    X_train = np.array(X_train, dtype=np.float64)\n",
    "    y_train = np.array(y_train, dtype=np.float64)\n",
    "\n",
    "    if data_val is not None:\n",
    "        X_val,y_val = feature_engineering(data_val,k,h,linear = True)\n",
    "        y_val[y_val == -1] = 0\n",
    "\n",
    "        X_val = np.array(X_val, dtype=np.float64)\n",
    "        y_val = np.array(y_val, dtype=np.float64)\n",
    "        history = model.fit(X_train, y_train,epochs=100, batch_size = 256, verbose=1,callbacks = [model_checkpoint_callback], validation_data = (X_val, y_val))\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train, epochs=100, batch_size = 256, verbose=1,callbacks = [model_checkpoint_callback])\n",
    "    \n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lasso_supervised(data, k, h,lambda_val = .7, data_val = None):\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(1, input_shape = (k+1,),kernel_regularizer = l1(lambda_val),activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    checkpoint_filepath = 'Test/Data/checkpoint.model.keras'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "    X_train,y_train = feature_engineering(data,k,h,linear = True)\n",
    "    y_train[y_train == -1] = 0\n",
    "    X_train = np.array(X_train, dtype=np.float64)\n",
    "    y_train = np.array(y_train, dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "    if data_val is not None:\n",
    "        X_val,y_val = feature_engineering(data_val,k,h,linear = True)\n",
    "        y_val[y_val == -1] = 0\n",
    "\n",
    "        X_val = np.array(X_val, dtype=np.float64)\n",
    "        y_val = np.array(y_val, dtype=np.float64)\n",
    "        history = model.fit(X_train, y_train,epochs=100, batch_size = 256, verbose=1,callbacks = [model_checkpoint_callback], validation_data = (X_val, y_val))\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train,epochs=100, batch_size = 256, verbose=1,callbacks = [model_checkpoint_callback])\n",
    "    \n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MLP_sharpeLoss(data, k, h,data_val = None):\n",
    "\n",
    "    model = Sequential([\n",
    "    Dropout(0, input_shape=(k+1,)),\n",
    "    Dense(2,activation = 'tanh'),\n",
    "    Dense(1,activation = 'tanh'),\n",
    "    ])\n",
    "\n",
    "    checkpoint_filepath = 'Test/Data/checkpoint.model.keras'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "    model.compile(optimizer='adam', loss=sharpe_loss(h = h))\n",
    "\n",
    "\n",
    "    X_train,y_train = feature_engineering(data,k,h,linear = False)\n",
    "    if data_val is not None:\n",
    "        X_val,y_val = feature_engineering(data_val,k,h,linear = True)\n",
    "\n",
    "        history = model.fit(X_train, y_train,epochs=100, batch_size = 256, verbose=1,callbacks = [model_checkpoint_callback], validation_data = (X_val, y_val))\n",
    "    else:\n",
    "    \n",
    "        history = model.fit(X_train, y_train, epochs=100, batch_size = 256, verbose=1,callbacks = [model_checkpoint_callback])\n",
    "    \n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Lasso_sharpeLoss(data, k, h,lambda_val = .7, data_val = None):\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(1, input_shape = (k+1,),kernel_regularizer = l1(lambda_val),activation= 'tanh')\n",
    "    ])\n",
    "\n",
    "    checkpoint_filepath = 'Test/Data/checkpoint.model.keras'\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "    model.compile(optimizer='adam', loss=sharpe_loss(h = h))\n",
    "\n",
    "    X_train,y_train = feature_engineering(data,k,h,linear = False)\n",
    "\n",
    "    if data_val is not None:\n",
    "        X_val,y_val = feature_engineering(data_val,k,h,linear = True)\n",
    "\n",
    "        history = model.fit(X_train, y_train,epochs=100, batch_size = 256, verbose=1,callbacks = [model_checkpoint_callback], validation_data = (X_val, y_val))\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train, epochs=100, batch_size = 256, verbose=1,callbacks = [model_checkpoint_callback])\n",
    "    \n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = '6mo' # khoảng thời gian làm backtest \n",
    "start_time = '2024-02-01'\n",
    "end_time = '2024-08-01'\n",
    "\n",
    "def EU_Stock_data():\n",
    "    \"\"\"Lấy dữ liệu giá Close của 50 công ty trên sàn Euro_STOXX 50 vào thời gian cho trước\"\"\"\n",
    "\n",
    "    stock_list = pd.read_html( 'https://en.wikipedia.org/wiki/EURO_STOXX_50')[4]['Ticker'][1:].to_list()\n",
    "    futures = pd.DataFrame(columns= stock_list) # danh sách mã\n",
    "    \n",
    "    # đặt index \n",
    "    time_index = list(yf.Ticker(stock_list[0]).history(period = time_range,start = start_time, end = end_time).index) \n",
    "\n",
    "    # xét từng mã\n",
    "    for symbol in stock_list:\n",
    "        df = yf.Ticker(symbol).history(period = time_range, start = start_time, end = end_time)\n",
    "        df = pd.DataFrame(df['Close']) # lấy giá close\n",
    "        i = 0\n",
    "        daily_return = []\n",
    "        # tinh daily return, = 0 trong ngày đầu tiên \n",
    "        for k in df['Close']:\n",
    "            if i != 0:\n",
    "                daily_return.append(float((k-i)/i))\n",
    "            else:\n",
    "                daily_return.append(float(0))\n",
    "            i = k\n",
    "        try:\n",
    "            futures[symbol] = daily_return\n",
    "        except:\n",
    "            while len(daily_return) < len(futures):\n",
    "                daily_return.insert(0,np.nan)\n",
    "            futures[symbol] = daily_return\n",
    "\n",
    "    futures.index = time_index\n",
    "\n",
    "    futures['Date'] = pd.to_datetime(futures.index, format='%Y-%m-%d')\n",
    "    futures.set_index('Date', inplace=True)\n",
    "\n",
    "    return futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_TSMOM(data, model,k,h,linear = False):\n",
    "\n",
    "    company = data.columns\n",
    "\n",
    "    signal = pd.DataFrame(index = data.index, columns= company)\n",
    "\n",
    "    features = []\n",
    "    for i in range(k,0,-1):\n",
    "        features.append(\"Before \" + str(i) + \" Day\")\n",
    "    features.append(\"Return Daily\")\n",
    "\n",
    "    for oo in company:\n",
    "        df = data[[oo]].copy()\n",
    "        \n",
    "        df.columns = [\"Return Daily\"]\n",
    "        df = construct_features_single_asset(df,k,h,linear = linear,test= True)\n",
    "\n",
    "        \n",
    "        X_test = df[features]\n",
    "        try:\n",
    "            if model.loss ==  'binary_crossentropy':\n",
    "                X_test['prediction'] = np.sign(model.predict(X_test) - 0.5)\n",
    "            else:\n",
    "                X_test['prediction'] = np.sign(model.predict(X_test))\n",
    "        except:\n",
    "            X_test['prediction'] = np.sign(model.predict(X_test))\n",
    "            X_test['prediction'][X_test['prediction'] == 0] = -1\n",
    "        for x,v in enumerate(X_test.index):\n",
    "            signal.loc[v,oo] = X_test.loc[v,'prediction']\n",
    "        \n",
    "        signal[oo] = signal[oo].ffill()\n",
    "        signal[oo] = signal[oo].fillna(0)\n",
    "\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Volatility_scale(data, ignore_na=False, adjust = True, com = 60, min_periods=0):\n",
    "    \"\"\"Scale data using ex ante volatility\"\"\"\n",
    "\n",
    "    # Lưu trữ index, tức thời gian \n",
    "    std_index = data.index\n",
    "\n",
    "    # chứa kết quả\n",
    "    daily_index = pd.DataFrame(index=std_index)\n",
    "\n",
    "    # xét từng cổ phiếu\n",
    "    for oo in data.columns:\n",
    "        returns = data[oo]  # Lấy ra các return\n",
    "        returns.dropna(inplace=True)  # xử lý null bằng zero\n",
    "\n",
    "        # Tính cumulative (cum) return , nhưng ko có thành phần - 1\n",
    "        ret_index = (1 + returns).cumprod()\n",
    "\n",
    "        # Tính daily volatility (vol)\n",
    "        day_vol = returns.ewm(ignore_na=ignore_na,\n",
    "                              adjust=adjust,\n",
    "                              com=com,\n",
    "                              min_periods=min_periods).std(bias=False)\n",
    "        \n",
    "        vol = day_vol * np.sqrt(252)  # scale lại theo 252 ngày active trading\n",
    "\n",
    "        # Join cum return và vol\n",
    "        ret_index = pd.concat([ret_index, vol], axis=1)\n",
    "        ret_index.columns = [oo, oo + '_Vol']  # Đặt tên cột cum return là tên cổ phiếu, bên cạnh là vol \n",
    "\n",
    "        # Join \n",
    "        daily_index = pd.concat([daily_index, ret_index], axis=1)\n",
    "\n",
    "    return daily_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_TSMOM(data, k, h, tolerance = 0,ignore_na = False, adjust = True, com = 60, min_periods = 0):\n",
    "    signal = pd.DataFrame(index = data.index)\n",
    "\n",
    "    # gọi hàm Volatility scale\n",
    "    daily_index = Volatility_scale(data,ignore_na=ignore_na,\n",
    "                          adjust=adjust,\n",
    "                          com=com,   \n",
    "                          min_periods = min_periods)\n",
    "\n",
    "    company = data.columns\n",
    "\n",
    "    for oo in company:\n",
    "        flag_h = 0\n",
    "        flag_k = k+1\n",
    "        df = pd.concat([daily_index[oo], daily_index[oo+\"_Vol\"]], axis=1)\n",
    "        df['rolling returns'] = df[oo].pct_change(k) # so sánh thay đổi ở ngày t với k ngày trước đó (tức t - k)\n",
    "        df['signal'] = 0.\n",
    "        for x, v in enumerate(df['rolling returns']):\n",
    "            if flag_h != 0:\n",
    "                # Bỏ qua giai đoạn hold, tránh bị tính lặp lại\n",
    "                flag_h = flag_h - 1\n",
    "                continue\n",
    "            # Bỏ qua thời gian cty chưa được lên sàn (nêu có)\n",
    "            if df[oo].isnull().iloc[x] == False:\n",
    "                # bỏ qua k ngày đầu vì chưa đủ k lookback\n",
    "                if flag_k != 0:\n",
    "                    flag_k = flag_k - 1\n",
    "                    continue\n",
    "            else: continue\n",
    "            try:\n",
    "                if df['rolling returns'].iloc[x-1] < tolerance:\n",
    "                    for h_period in range(0,h):\n",
    "                        # rolling return < 0, short rồi giữ trong h ngày, tính pnl, leverage///\n",
    "                        df['signal'].iloc[x + h_period] = -1\n",
    "                \n",
    "                elif df['rolling returns'].iloc[x-1] > tolerance:\n",
    "                    for h_period in range(0,h):\n",
    "                        # rolling return > 0, long rồi giữ trong h ngày, tính pnl, leverage///\n",
    "                        df['signal'].iloc[x + h_period] = 1\n",
    "\n",
    "            except:pass\n",
    "            \n",
    "\n",
    "            # Đặt flag holding là h - 1, để qua vòng for mới bỏ qua ngày hold, tránh bị tính lặp lại\n",
    "            if df['rolling returns'].iloc[x-1] != tolerance: flag_h = h - 1\n",
    "\n",
    "        signal = pd.concat([signal, df['signal']], axis=1)\n",
    "\n",
    "    signal.columns = data.columns\n",
    "    \n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data,signal,k,h,  vol_flag = 1, target_vol = 0.2, ignore_na = False, adjust = True, com = 60, min_periods = 0):\n",
    "    \n",
    "    pnl = pd.DataFrame(index=data.index)\n",
    "    leverage = pd.DataFrame(index = data.index)\n",
    "\n",
    "    # gọi hàm Volatility scale\n",
    "    daily_index = Volatility_scale(data,ignore_na=ignore_na,\n",
    "                          adjust=adjust,\n",
    "                          com=com,   \n",
    "                          min_periods = min_periods)\n",
    "\n",
    "    company = data.columns\n",
    "\n",
    "    # Volatility settings\n",
    "    vol_flag = vol_flag    # Set flag to 1 for vol targeting\n",
    "    if vol_flag == 1:\n",
    "        target_vol = target_vol \n",
    "    else:\n",
    "        target_vol = 'no target vol'\n",
    "    \n",
    "\n",
    "    for oo in company:\n",
    "        flag_h = 0\n",
    "        flag_k = k+1\n",
    "        df = pd.concat([daily_index[oo], daily_index[oo+\"_Vol\"]], axis=1)\n",
    "\n",
    "        df['pnl'] = 0. \n",
    "        df['leverage'] = 0.\n",
    "        for x, v in enumerate(df['pnl']):\n",
    "            if flag_h != 0:\n",
    "                # Bỏ qua giai đoạn hold, tránh bị tính lặp lại\n",
    "                flag_h = flag_h - 1\n",
    "                continue\n",
    "            # Bỏ qua thời gian cty chưa được lên sàn (nêu có)\n",
    "            if df[oo].isnull().iloc[x] == False:\n",
    "                # bỏ qua k ngày đầu vì chưa đủ k lookback\n",
    "                if flag_k != 0:\n",
    "                    flag_k = flag_k - 1\n",
    "                    continue\n",
    "            else: continue\n",
    "            try:\n",
    "                if signal[oo].iloc[x] == -1:\n",
    "                    for h_period in range(0,h):\n",
    "                        if vol_flag == 1:\n",
    "                            df['pnl'].iloc[x + h_period] = (1 - df[oo].iloc[x + h_period] / df[oo].iloc[x - 1 + h_period]) * \\\n",
    "                                target_vol / df[oo+\"_Vol\"].iloc[x -1] \n",
    "                            df['leverage'].iloc[x + h_period] = target_vol / df[oo+\"_Vol\"].iloc[x -1]\n",
    "                        else:\n",
    "                            df['pnl'].iloc[x + h_period] = (1 - df[oo].iloc[x + h_period] / df[oo].iloc[x - 1 + h_period])\n",
    "                            df['leverage'].iloc[x+h_period] = 1\n",
    "                elif signal[oo].iloc[x] == 1:\n",
    "                    for h_period in range(0,h):\n",
    "                        if vol_flag == 1:\n",
    "                            df['pnl'].iloc[x + h_period] = (df[oo].iloc[x + h_period] / df[oo].iloc[x - 1 + h_period] - 1) * \\\n",
    "                                    target_vol / df[oo+\"_Vol\"].iloc[x - 1]\n",
    "                            df['leverage'].iloc[x+h_period] = target_vol / df[oo+\"_Vol\"].iloc[x -1]\n",
    "                        else:\n",
    "                            df['pnl'].iloc[x + h_period] = (df[oo].iloc[x + h_period] / df[oo].iloc[x - 1 + h_period] - 1)\n",
    "                            df['leverage'].iloc[x+h_period] = 1\n",
    "            except:pass\n",
    "            \n",
    "            if signal[oo].iloc[x] == 1 or signal[oo].iloc[x] == -1 : flag_h = h - 1\n",
    "\n",
    "\n",
    "        leverage = pd.concat([leverage, df['leverage']], axis = 1)\n",
    "        pnl = pd.concat([pnl, df['pnl']], axis=1)\n",
    "\n",
    "    pnl.columns = data.columns\n",
    "    leverage.columns = data.columns\n",
    "\n",
    "    return [pnl,leverage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy_daily_return(pnl):\n",
    "    \n",
    "    return pnl.mean(skipna = False, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
